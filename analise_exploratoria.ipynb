{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carregar base de dados via URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir a URL\n",
    "url = \"http://www.ipeadata.gov.br/ExibeSerie.aspx?module=m&serid=1650971490&oper=view\"\n",
    "\n",
    "# Fazer a requisi√ß√£o √† p√°gina\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\" P√°gina acessada com sucesso.\")\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_csv(\"dados/dados_petroleo_brent_2005_2025.csv\")\n",
    "        print(\"Arquivo carregado com sucesso!\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: O arquivo local {df} n√£o foi encontrado.\")\n",
    "        df = None  \n",
    "    print(f\" Erro ao acessar a p√°gina. C√≥digo: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Parsear o HTML e localizar a tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verificar se a requisi√ß√£o foi bem-sucedida\n",
    "if response.status_code == 200:\n",
    "    # Parsear o HTML\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Procurar a tabela com a classe espec√≠fica\n",
    "    table = soup.find('table', {'class': 'dxgvTable'})\n",
    "    \n",
    "    if table:\n",
    "        print(\" Tabela encontrada, iniciando a cria√ß√£o do DataFrame...\")\n",
    "    else:\n",
    "        print(\" Tabela n√£o encontrada na p√°gina.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Criar o DataFrame inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if table:\n",
    "    # Ler a tabela HTML para um DataFrame Pandas\n",
    "    df = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Renomear as colunas\n",
    "    df.columns = [\"Data\", \"Pre√ßo (US$)\"]\n",
    "\n",
    "    # Exibir as 5 primeiras linhas para conferir\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Limpeza inicial dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **4. Limpeza inicial dos dados**\n",
    "# Filtrar apenas linhas onde a coluna 'Data' √© v√°lida\n",
    "print(\"Limpando dados inv√°lidos na coluna 'Data'...\")\n",
    "df = df[df[\"Data\"].str.match(r\"\\d{2}/\\d{2}/\\d{4}\", na=False)]\n",
    "\n",
    "# Converter a coluna \"Data\" para datetime\n",
    "df[\"Data\"] = pd.to_datetime(df[\"Data\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "\n",
    "# Remover valores nulos gerados pela convers√£o\n",
    "df = df.dropna(subset=[\"Data\"]).reset_index(drop=True)\n",
    "\n",
    "# Exibir informa√ß√µes sobre o DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 5. Ajuste dos valores na coluna ‚ÄúPre√ßo (US$)‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir a v√≠rgula por ponto e converter para float\n",
    "df[\"Pre√ßo (US$)\"] = df[\"Pre√ßo (US$)\"].str.replace(\",\", \".\").astype(float) / 100\n",
    "\n",
    "# Exibir estat√≠sticas descritivas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  6. Filtrar os dados no intervalo de 2005 a 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manter apenas os dados entre 2005 e 2025\n",
    "df = df[(df[\"Data\"] >= \"2005-01-01\") & (df[\"Data\"] <= \"2025-12-31\")]\n",
    "\n",
    "# Resetar o √≠ndice\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Exibir as 5 primeiras linhas ap√≥s a filtragem\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 7. Verifica√ß√£o da Qualidade dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir estat√≠sticas descritivas\n",
    "print(\" Estat√≠sticas descritivas:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Verificar a contagem de valores nulos\n",
    "print(\"\\n Contagem de valores nulos:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Mostrar informa√ß√µes do DataFrame\n",
    "print(\"\\n Estrutura do DataFrame:\")\n",
    "df.info()\n",
    "\n",
    "# Verificar se h√° datas duplicadas\n",
    "duplicadas = df[\"Data\"].value_counts()\n",
    "if any(duplicadas > 1):\n",
    "    print(\"\\n TEM DATA DUPLICADAS!\")\n",
    "else:\n",
    "    print(\"\\n N√ÉO TEM DATA DUPLICADAS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Salvar os dados tratados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar os dados limpos em CSV\n",
    "df.to_csv(\"dados/dados_petroleo_brent_2005_2025.csv\", index=False, encoding=\"utf-8\")\n",
    "print(f\"Dados salvos com sucesso em {df}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Evolu√ß√£o do Pre√ßo ao Longo do Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolu√ß√£o do pre√ßo ao longo do tempo\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=df[\"Data\"], y=df[\"Pre√ßo (US$)\"], linewidth=2)\n",
    "plt.title(\"Evolu√ß√£o do Pre√ßo do Petr√≥leo Brent (2005-2025)\")\n",
    "plt.xlabel(\"Ano\")\n",
    "plt.ylabel(\"Pre√ßo (US$)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 11. Distribui√ß√£o dos Pre√ßos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df[\"Pre√ßo (US$)\"], bins=30, kde=True)\n",
    "plt.title(\"Distribui√ß√£o dos Pre√ßos do Petr√≥leo Brent\")\n",
    "plt.xlabel(\"Pre√ßo (US$)\")\n",
    "plt.ylabel(\"Frequ√™ncia\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Boxplot dos Pre√ßos ao Longo do Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Boxplot dos pre√ßos ao longo do tempo\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=df[\"Data\"].dt.year, y=\"Pre√ßo (US$)\", data=df)\n",
    "plt.title(\"Boxplot dos Pre√ßos do Petr√≥leo por Ano\")\n",
    "plt.xlabel(\"Ano\")\n",
    "plt.ylabel(\"Pre√ßo (US$)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Pre√ßo M√©dio por Ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_yearly = df.groupby(df[\"Data\"].dt.year)[\"Pre√ßo (US$)\"].mean().reset_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Data\", y=\"Pre√ßo (US$)\", data=df_yearly)\n",
    "plt.title(\"Pre√ßo M√©dio Anual do Petr√≥leo Brent\")\n",
    "plt.xlabel(\"Ano\")\n",
    "plt.ylabel(\"Pre√ßo M√©dio (US$)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Evolu√ß√£o do Pre√ßo com Eventos Geopol√≠ticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=\"Data\", y=\"Pre√ßo (US$)\", data=df, label=\"Pre√ßo do Petr√≥leo\")\n",
    "plt.axvline(pd.Timestamp(\"2008-09-15\"), color=\"red\", linestyle=\"--\", label=\"Crise Financeira 2008\")\n",
    "plt.axvline(pd.Timestamp(\"2020-03-01\"), color=\"blue\", linestyle=\"--\", label=\"In√≠cio da Pandemia COVID-19\")\n",
    "plt.title(\"Evolu√ß√£o do Pre√ßo do Petr√≥leo Brent com Eventos Geopol√≠ticos\")\n",
    "plt.xlabel(\"Ano\")\n",
    "plt.ylabel(\"Pre√ßo (US$)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 15. Varia√ß√£o Percentual Mensal do Pre√ßo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"Varia√ß√£o (%)\"] = df[\"Pre√ßo (US$)\"].pct_change() * 100\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=\"Data\", y=\"Varia√ß√£o (%)\", data=df)\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.title(\"Varia√ß√£o Percentual Mensal do Pre√ßo do Petr√≥leo\")\n",
    "plt.xlabel(\"Ano\")\n",
    "plt.ylabel(\"Varia√ß√£o (%)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. Compara√ß√£o Antes e Depois da Crise de 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_crise_2008 = df[(df[\"Data\"] >= \"2007-01-01\") & (df[\"Data\"] <= \"2009-12-31\")]\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=\"Data\", y=\"Pre√ßo (US$)\", data=df_crise_2008)\n",
    "plt.axvline(pd.Timestamp(\"2008-09-15\"), color=\"red\", linestyle=\"--\", label=\"Crise Financeira 2008\")\n",
    "plt.title(\"Pre√ßo do Petr√≥leo Antes e Ap√≥s a Crise de 2008\")\n",
    "plt.xlabel(\"Ano\")\n",
    "plt.ylabel(\"Pre√ßo (US$)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Decomposi√ß√£o da S√©rie Temporal do Pre√ßo do Petr√≥leo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"dados/dados_petroleo_brent_2005_2025.csv\")\n",
    "df[\"Data\"] = pd.to_datetime(df[\"Data\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "\n",
    "df.set_index(\"Data\", inplace=True)\n",
    "\n",
    "\n",
    "decomposition = seasonal_decompose(df[\"Pre√ßo (US$)\"], model=\"additive\", period=365)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(df[\"Pre√ßo (US$)\"], label=\"S√©rie Original\", color=\"orange\")\n",
    "plt.legend()\n",
    "plt.title(\"Decomposi√ß√£o da S√©rie Temporal - Pre√ßo do Petr√≥leo Brent\")\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(decomposition.trend, label=\"Tend√™ncia\", color=\"red\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(decomposition.seasonal, label=\"Sazonalidade\", color=\"green\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(decomposition.resid, label=\"Res√≠duo\", color=\"purple\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18. Testando o Modelo Prophet para Previs√£o do Pre√ßo do Petr√≥leo Brent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados hist√≥ricos\n",
    "try:\n",
    "    df = pd.read_csv(\"dados/dados_petroleo_brent_2005_2025.csv\")\n",
    "    print(\"Arquivo carregado com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o arquivo: {e}\")\n",
    "    raise\n",
    "\n",
    "# Converter a coluna \"Data\" para o formato datetime\n",
    "df[\"Data\"] = pd.to_datetime(df[\"Data\"])\n",
    "\n",
    "# Ordenar os dados por data\n",
    "df = df.sort_values(by=\"Data\")\n",
    "\n",
    "# Exibir as 5 primeiras linhas para confer√™ncia\n",
    "df.head()\n",
    "\n",
    "\n",
    "#3. Divis√£o dos Dados em Treino e Teste\n",
    "\n",
    "# Definir per√≠odo de treino e teste\n",
    "train = df[df[\"Data\"] < \"2023-01-01\"].copy()\n",
    "test = df[df[\"Data\"] >= \"2023-01-01\"].copy()\n",
    "\n",
    "# Exibir quantidades de dados\n",
    "print(f\"Dados de treino: {len(train)} linhas\")\n",
    "print(f\"Dados de teste: {len(test)} linhas\")\n",
    "\n",
    "\n",
    "# Renomear colunas para o formato do Prophet\n",
    "df_prophet = df.rename(columns={\"Data\": \"ds\", \"Pre√ßo (US$)\": \"y\"})\n",
    "\n",
    "# Criar e treinar o modelo Prophet\n",
    "model = Prophet()\n",
    "model.fit(df_prophet)\n",
    "\n",
    "\n",
    "# Converter conjunto de teste para o formato do Prophet\n",
    "future_test = test.rename(columns={\"Data\": \"ds\"})\n",
    "\n",
    "# Gerar previs√µes apenas para o per√≠odo de teste\n",
    "forecast_test = model.predict(future_test)\n",
    "\n",
    "# Adicionar as previs√µes ao DataFrame de teste\n",
    "test[\"Previs√£o\"] = forecast_test[\"yhat\"].values\n",
    "\n",
    "# Exibir as 5 primeiras previs√µes\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar previs√µes para o futuro (1 ano)\n",
    "future = model.make_future_dataframe(periods=360)\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Gr√°fico das previs√µes do modelo Prophet\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "model.plot(forecast, ax=ax)\n",
    "ax.legend([\"Hist√≥rico\", \"Previs√£o\", \"Intervalo de Confian√ßa\"])\n",
    "plt.title(\"Modelo Prophet - Previs√£o do Pre√ßo do Petr√≥leo Brent\")\n",
    "plt.show()\n",
    "\n",
    "# Calcular RMSE corretamente\n",
    "rmse = mean_squared_error(test[\"Pre√ßo (US$)\"], test[\"Previs√£o\"]) ** 0.5\n",
    "print(f\"RMSE (Prophet): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19. Modelo Prophet + XGBoost para Previs√£o Ajustada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"dados/dados_petroleo_brent_2005_2025.csv\")\n",
    "    print(\"Arquivo carregado com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o arquivo: {e}\")\n",
    "    raise\n",
    "\n",
    "# Verificar colunas esperadas\n",
    "if \"Data\" not in df.columns or \"Pre√ßo (US$)\" not in df.columns:\n",
    "    raise ValueError(\"O arquivo CSV deve conter as colunas 'Data' e 'Pre√ßo (US$)'.\")\n",
    "\n",
    "# Converter colunas para os tipos corretos\n",
    "df[\"ds\"] = pd.to_datetime(df[\"Data\"], errors=\"coerce\")  # Converte para datetime\n",
    "df[\"y\"] = pd.to_numeric(df[\"Pre√ßo (US$)\"], errors=\"coerce\")  # Converte para num√©rico\n",
    "\n",
    "# Verificar valores ausentes\n",
    "if df[\"ds\"].isnull().any() or df[\"y\"].isnull().any():\n",
    "    print(\"Aten√ß√£o: H√° valores ausentes nas colunas 'Data' ou 'Pre√ßo (US$)'. Preenchendo valores ausentes...\")\n",
    "    df[\"ds\"].fillna(method=\"ffill\", inplace=True)  # Preenche datas ausentes\n",
    "    df[\"y\"].fillna(method=\"ffill\", inplace=True)  # Preenche pre√ßos ausentes\n",
    "\n",
    "# Ordenar os dados corretamente\n",
    "df = df.sort_values(by=\"ds\").reset_index(drop=True)\n",
    "\n",
    "# Remover duplicatas\n",
    "if df.duplicated(subset=[\"ds\"]).any():\n",
    "    print(\"Aten√ß√£o: H√° duplicatas na coluna 'Data'. Removendo duplicatas...\")\n",
    "    df = df.drop_duplicates(subset=[\"ds\"])\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame tratado\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do Modelo Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar e treinar o modelo Prophet\n",
    "prophet = Prophet()\n",
    "prophet.fit(df[[\"ds\", \"y\"]])  # Usando apenas as colunas necess√°rias\n",
    "\n",
    "# Definir a data final desejada (31 de dezembro de 2026)\n",
    "data_final_desejada = pd.to_datetime(\"2026-12-31\")\n",
    "\n",
    "# Calcular o n√∫mero de dias at√© essa data\n",
    "ultima_data_df = df[\"ds\"].max()\n",
    "dias_ate_2026 = (data_final_desejada - ultima_data_df).days\n",
    "\n",
    "# Criar previs√µes do Prophet at√© o final de 2026\n",
    "future = prophet.make_future_dataframe(periods=dias_ate_2026)\n",
    "prophet_future = prophet.predict(future)\n",
    "\n",
    "# Mesclar previs√µes do Prophet com o DataFrame original\n",
    "df = df.merge(prophet_future[[\"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"]], on=\"ds\", how=\"left\")\n",
    "\n",
    "# Exibir as 5 primeiras previs√µes do Prophet\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste das Previs√µes com XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renomear colunas para facilitar a interpreta√ß√£o\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"ds\": \"Data\",\n",
    "        \"y\": \"Pre√ßo Real\",\n",
    "        \"yhat\": \"Pre√ßo Previsto\",\n",
    "        \"yhat_lower\": \"Intervalo Inferior\",\n",
    "        \"yhat_upper\": \"Intervalo Superior\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Criar a coluna de res√≠duos\n",
    "df[\"Res√≠duo\"] = df[\"Pre√ßo Real\"] - df[\"Pre√ßo Previsto\"]\n",
    "# Remover colunas duplicadas ap√≥s a renomea√ß√£o\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "# Criar features para o modelo XGBoost (lags dos res√≠duos)\n",
    "for i in range(1, 8):  # Criar lags de 1 a 7 dias\n",
    "    df[f\"Res√≠duo_Lag_{i}\"] = df[\"Res√≠duo\"].shift(i)\n",
    "\n",
    "# Remover linhas com valores ausentes gerados pelos lags\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Dividir os dados em treino e teste (80% para treino)\n",
    "train_size = int(len(df) * 0.8)\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]\n",
    "\n",
    "# Definir features e target para XGBoost\n",
    "features = [f\"Res√≠duo_Lag_{i}\" for i in range(1, 8)]\n",
    "X_train, y_train = train[features], train[\"Res√≠duo\"]\n",
    "X_test, y_test = test[features], test[\"Res√≠duo\"]\n",
    "\n",
    "# Treinar o modelo XGBoost\n",
    "model_xgb = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previs√µes com XGBoost\n",
    "y_pred_residuo = model_xgb.predict(X_test)\n",
    "\n",
    "# Ajustar as previs√µes do Prophet com os res√≠duos previstos pelo XGBoost\n",
    "test[\"Pre√ßo Previsto Ajustado\"] = test[\"Pre√ßo Previsto\"] + y_pred_residuo\n",
    "\n",
    "# Exibir as primeiras previs√µes ajustadas\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular m√©tricas de desempenho para as previs√µes ajustadas\n",
    "rmse_ajustado = np.sqrt(mean_squared_error(test['Pre√ßo Real'], test['Pre√ßo Previsto Ajustado']))\n",
    "mae_ajustado = mean_absolute_error(test['Pre√ßo Real'], test['Pre√ßo Previsto Ajustado'])\n",
    "mape_ajustado = np.mean(np.abs((test['Pre√ßo Real'] - test['Pre√ßo Previsto Ajustado']) / test['Pre√ßo Real'])) * 100\n",
    "\n",
    "print(f\"RMSE (Ajustado): {rmse_ajustado}\")\n",
    "print(f\"MAE (Ajustado): {mae_ajustado}\")\n",
    "print(f\"MAPE (Ajustado): {mape_ajustado}%\")\n",
    "\n",
    "# # Salvar os modelos treinados\n",
    "# joblib.dump(prophet, 'modelo_prophet.pkl')  # Salvar o modelo Prophet\n",
    "# joblib.dump(model_xgb, 'modelo_xgboost.pkl')  # Salvar o modelo XGBoost\n",
    "# print(\"Modelos salvos com sucesso!\")\n",
    "\n",
    "# Criar previs√µes para 2025-2026\n",
    "future_df = prophet_future[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].copy()\n",
    "future_df = future_df[future_df['ds'] >= '2025-01-01']  # Filtrar apenas anos futuros\n",
    "\n",
    "# Criar features de calend√°rio para o futuro\n",
    "future_df['year'] = future_df['ds'].dt.year\n",
    "future_df['month'] = future_df['ds'].dt.month\n",
    "future_df['day'] = future_df['ds'].dt.day\n",
    "future_df['dayofweek'] = future_df['ds'].dt.dayofweek\n",
    "\n",
    "# Criar lags com os √∫ltimos dados dispon√≠veis\n",
    "for i in range(1, 8):\n",
    "    future_df[f'Res√≠duo_Lag_{i}'] = df[f'Res√≠duo_Lag_{i}'].iloc[-1]\n",
    "\n",
    "# Aplicar XGBoost para corre√ß√£o da previs√£o de 2025-2026\n",
    "future_X = future_df[features]\n",
    "y_pred_residuo_future = model_xgb.predict(future_X)\n",
    "future_df['Pre√ßo Previsto Ajustado'] = future_df['yhat'] + y_pred_residuo_future\n",
    "\n",
    "# Criar intervalo de confian√ßa para a previs√£o corrigida\n",
    "future_df['Pre√ßo Previsto Ajustado Inferior'] = future_df['yhat_lower'] + y_pred_residuo_future\n",
    "future_df['Pre√ßo Previsto Ajustado Superior'] = future_df['yhat_upper'] + y_pred_residuo_future\n",
    "\n",
    "# Criar t√≠tulo com m√©tricas\n",
    "title_text = (f\"Corre√ß√£o de Previs√£o Prophet com XGBoost\\n\"\n",
    "              f\"RMSE: {rmse_ajustado:.2f}, MAE: {mae_ajustado:.2f}, MAPE: {mape_ajustado:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiza√ß√£o das Previs√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotar resultados\n",
    "plt.figure(figsize=(14, 6))\n",
    "df['Data'] = pd.to_datetime(df['Data'])\n",
    "test['Data'] = pd.to_datetime(test['Data'])\n",
    "future_df['ds'] = pd.to_datetime(future_df['ds'])\n",
    "\n",
    "# Adicionando o hist√≥rico completo ao gr√°fico\n",
    "plt.plot(df['Data'], df['Pre√ßo Real'], label=\"Hist√≥rico Completo (Real)\", color=\"blue\", linewidth=1.2)\n",
    "\n",
    "# Adicionando os dados reais do conjunto de teste\n",
    "plt.plot(test['Data'], test['Pre√ßo Real'], label=\"Teste (Real)\", color=\"green\", linewidth=1.5)\n",
    "\n",
    "# Adicionando a previs√£o do Prophet\n",
    "plt.plot(df['Data'], df['Pre√ßo Previsto'], label=\"Previs√£o Prophet\", linestyle=\"--\", color=\"orange\", linewidth=1.5)\n",
    "\n",
    "# Adicionando a previs√£o corrigida\n",
    "plt.plot(test['Data'], test['Pre√ßo Previsto Ajustado'], label=\"Previs√£o Corrigida (Prophet + XGBoost)\", linestyle=\"-\", color=\"purple\", linewidth=1.5)\n",
    "\n",
    "plt.plot(future_df['ds'], future_df['Pre√ßo Previsto Ajustado'], label=\"Previs√£o Futura Corrigida (2025-2026)\", linestyle=\"-\", color=\"red\", linewidth=1.5)\n",
    "\n",
    "# Adicionar intervalo de confian√ßa\n",
    "plt.fill_between(future_df['ds'], future_df['Pre√ßo Previsto Ajustado Inferior'], future_df['Pre√ßo Previsto Ajustado Superior'], color='gray', alpha=0.3, label=\"Intervalo de Confian√ßa\")\n",
    "\n",
    "plt.title(title_text)\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Pre√ßo (US$)\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar as Previs√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar tabela com as previs√µes futuras (2025-2026)\n",
    "future_df = prophet_future[[\"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"]].copy()\n",
    "future_df = future_df[future_df[\"ds\"] >= \"2025-01-01\"]  # Filtrar apenas anos futuros\n",
    "\n",
    "# Criar lags para previs√µes futuras\n",
    "for i in range(1, 8):\n",
    "    future_df[f\"Res√≠duo_Lag_{i}\"] = df[f\"Res√≠duo_Lag_{i}\"].iloc[-1]\n",
    "\n",
    "# Aplicar XGBoost para corre√ß√£o da previs√£o futura\n",
    "future_X = future_df[features]\n",
    "y_pred_residuo_future = model_xgb.predict(future_X)\n",
    "future_df[\"Pre√ßo Previsto Ajustado\"] = future_df[\"yhat\"] + y_pred_residuo_future\n",
    "\n",
    "# Salvar as previs√µes ajustadas\n",
    "future_df.to_csv(\"dados/previsoes_futuras.csv\", index=False)\n",
    "print(\"Previs√µes futuras salvas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar os dados\n",
    "try:\n",
    "    df = pd.read_csv(\"dados/dados_petroleo_brent_2005_2025.csv\")\n",
    "    print(\"Arquivo carregado com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o arquivo: {e}\")\n",
    "    raise\n",
    "\n",
    "# Verificar colunas esperadas\n",
    "if 'Data' not in df.columns or 'Pre√ßo (US$)' not in df.columns:\n",
    "    raise ValueError(\"O arquivo CSV deve conter as colunas 'Data' e 'Pre√ßo (US$)'.\")\n",
    "\n",
    "# Converter colunas para os tipos corretos\n",
    "df['ds'] = pd.to_datetime(df['Data'], errors='coerce')  # Converte para datetime\n",
    "df['y'] = pd.to_numeric(df['Pre√ßo (US$)'], errors='coerce')  # Converte para num√©rico\n",
    "\n",
    "# Verificar valores ausentes\n",
    "if df['ds'].isnull().any() or df['y'].isnull().any():\n",
    "    print(\"Aten√ß√£o: H√° valores ausentes nas colunas 'Data' ou 'Pre√ßo (US$)'. Preenchendo valores ausentes...\")\n",
    "    df['ds'].fillna(method='ffill', inplace=True)  # Preenche datas ausentes\n",
    "    df['y'].fillna(method='ffill', inplace=True)  # Preenche pre√ßos ausentes\n",
    "\n",
    "# Ordenar os dados corretamente\n",
    "df = df.sort_values(by='ds').reset_index(drop=True)\n",
    "\n",
    "# Verificar e remover duplicatas na coluna 'ds' (Data)\n",
    "if df.duplicated(subset=['ds']).any():\n",
    "    print(\"Aten√ß√£o: H√° duplicatas na coluna 'Data'. Removendo duplicatas...\")\n",
    "    df = df.drop_duplicates(subset=['ds'])\n",
    "\n",
    "# Treinar o modelo Prophet\n",
    "prophet = Prophet()\n",
    "prophet.fit(df[['ds', 'y']])  # Usando apenas as colunas 'ds' e 'y'\n",
    "\n",
    "# Definir a data final desejada (31 de dezembro de 2026)\n",
    "data_final_desejada = pd.to_datetime('2026-12-31')\n",
    "\n",
    "# Calcular o n√∫mero de dias at√© a data final desejada\n",
    "ultima_data_df = df['ds'].max()\n",
    "dias_ate_2026 = (data_final_desejada - ultima_data_df).days\n",
    "\n",
    "# Criar previs√µes do Prophet at√© o final de 2026\n",
    "future = prophet.make_future_dataframe(periods=dias_ate_2026)  \n",
    "prophet_future = prophet.predict(future)\n",
    "\n",
    "# Mesclar previs√µes do Prophet com o DataFrame original\n",
    "df = df.merge(prophet_future[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], on='ds', how='left')\n",
    "\n",
    "# Verificar duplicatas ap√≥s a mesclagem\n",
    "if df.duplicated(subset=['ds']).any():\n",
    "    print(\"Aten√ß√£o: H√° duplicatas ap√≥s a mesclagem. Removendo duplicatas...\")\n",
    "    df = df.drop_duplicates(subset=['ds'])\n",
    "\n",
    "# Renomear as colunas de forma clara e estruturada\n",
    "mapeamento_colunas = {\n",
    "    'ds': 'Data',\n",
    "    'y': 'Pre√ßo Real',\n",
    "    'yhat': 'Pre√ßo Previsto',\n",
    "    'yhat_lower': 'Intervalo Inferior',\n",
    "    'yhat_upper': 'Intervalo Superior'\n",
    "}\n",
    "\n",
    "df.rename(columns=mapeamento_colunas, inplace=True)\n",
    "\n",
    "# Remover colunas duplicadas ap√≥s a renomea√ß√£o\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "# Calcular res√≠duos (erros) do Prophet\n",
    "df['Res√≠duo'] = df['Pre√ßo Real'] - df['Pre√ßo Previsto']\n",
    "\n",
    "# Criar features para o modelo XGBoost\n",
    "# Adicionar lags dos res√≠duos como features\n",
    "for i in range(1, 8): \n",
    "    df[f'Res√≠duo_Lag_{i}'] = df['Res√≠duo'].shift(i)\n",
    "\n",
    "# Remover linhas com valores ausentes gerados pelos lags\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_size = int(len(df) * 0.8)  # 80% para treino, 20% para teste\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]\n",
    "\n",
    "# Definir features e target para o XGBoost\n",
    "features = [f'Res√≠duo_Lag_{i}' for i in range(1, 8)]  \n",
    "X_train = train[features]\n",
    "y_train = train['Res√≠duo']\n",
    "X_test = test[features]\n",
    "y_test = test['Res√≠duo']\n",
    "\n",
    "# Treinar o modelo XGBoost\n",
    "model_xgb = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previs√µes com o XGBoost\n",
    "y_pred_residuo = model_xgb.predict(X_test)\n",
    "\n",
    "# Ajustar as previs√µes do Prophet com os res√≠duos previstos pelo XGBoost\n",
    "test['Pre√ßo Previsto Ajustado'] = test['Pre√ßo Previsto'] + y_pred_residuo\n",
    "\n",
    "# Calcular m√©tricas de desempenho para as previs√µes ajustadas\n",
    "rmse_ajustado = np.sqrt(mean_squared_error(test['Pre√ßo Real'], test['Pre√ßo Previsto Ajustado']))\n",
    "mae_ajustado = mean_absolute_error(test['Pre√ßo Real'], test['Pre√ßo Previsto Ajustado'])\n",
    "mape_ajustado = np.mean(np.abs((test['Pre√ßo Real'] - test['Pre√ßo Previsto Ajustado']) / test['Pre√ßo Real'])) * 100\n",
    "\n",
    "print(f\"RMSE (Ajustado): {rmse_ajustado}\")\n",
    "print(f\"MAE (Ajustado): {mae_ajustado}\")\n",
    "print(f\"MAPE (Ajustado): {mape_ajustado}%\")\n",
    "\n",
    "# Salvar os modelos treinados\n",
    "joblib.dump(prophet, 'dados/modelo_prophet.pkl')  \n",
    "joblib.dump(model_xgb, 'dados/modelo_xgboost.pkl')  \n",
    "print(\"Modelos salvos com sucesso!\")\n",
    "\n",
    "#  Criar previs√µes para 2025-2026\n",
    "future_df = prophet_future[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].copy()\n",
    "future_df = future_df[future_df['ds'] >= '2025-01-01']  # Filtrar apenas anos futuros\n",
    "\n",
    "# Criar features de calend√°rio para o futuro\n",
    "future_df['year'] = future_df['ds'].dt.year\n",
    "future_df['month'] = future_df['ds'].dt.month\n",
    "future_df['day'] = future_df['ds'].dt.day\n",
    "future_df['dayofweek'] = future_df['ds'].dt.dayofweek\n",
    "\n",
    "# Criar lags com os √∫ltimos dados dispon√≠veis\n",
    "for i in range(1, 8):\n",
    "    future_df[f'Res√≠duo_Lag_{i}'] = df[f'Res√≠duo_Lag_{i}'].iloc[-1]\n",
    "\n",
    "# Aplicar XGBoost para corre√ß√£o da previs√£o de 2025-2026\n",
    "future_X = future_df[features]\n",
    "y_pred_residuo_future = model_xgb.predict(future_X)\n",
    "future_df['Pre√ßo Previsto Ajustado'] = future_df['yhat'] + y_pred_residuo_future\n",
    "\n",
    "# Criar intervalo de confian√ßa para a previs√£o corrigida\n",
    "future_df['Pre√ßo Previsto Ajustado Inferior'] = future_df['yhat_lower'] + y_pred_residuo_future\n",
    "future_df['Pre√ßo Previsto Ajustado Superior'] = future_df['yhat_upper'] + y_pred_residuo_future\n",
    "\n",
    "# Criar t√≠tulo com m√©tricas\n",
    "title_text = (f\"Corre√ß√£o de Previs√£o Prophet com XGBoost\\n\"\n",
    "              f\"RMSE: {rmse_ajustado:.2f}, MAE: {mae_ajustado:.2f}, MAPE: {mape_ajustado:.2f}%\")\n",
    "\n",
    "\n",
    "# Plotar resultados\n",
    "plt.figure(figsize=(14, 6))\n",
    "df['Data'] = pd.to_datetime(df['Data'])\n",
    "test['Data'] = pd.to_datetime(test['Data'])\n",
    "future_df['ds'] = pd.to_datetime(future_df['ds'])\n",
    "\n",
    "# Adicionando o hist√≥rico completo ao gr√°fico\n",
    "plt.plot(df['Data'], df['Pre√ßo Real'], label=\"Hist√≥rico Completo (Real)\", color=\"blue\", linewidth=1.2)\n",
    "\n",
    "# Adicionando os dados reais do conjunto de teste\n",
    "plt.plot(test['Data'], test['Pre√ßo Real'], label=\"Teste (Real)\", color=\"green\", linewidth=1.5)\n",
    "\n",
    "# Adicionando a previs√£o do Prophet\n",
    "plt.plot(df['Data'], df['Pre√ßo Previsto'], label=\"Previs√£o Prophet\", linestyle=\"--\", color=\"orange\", linewidth=1.5)\n",
    "\n",
    "# Adicionando a previs√£o corrigida\n",
    "plt.plot(test['Data'], test['Pre√ßo Previsto Ajustado'], label=\"Previs√£o Corrigida (Prophet + XGBoost)\", linestyle=\"-\", color=\"purple\", linewidth=1.5)\n",
    "\n",
    "\n",
    "plt.plot(future_df['ds'], future_df['Pre√ßo Previsto Ajustado'], label=\"Previs√£o Futura Corrigida (2025-2026)\", linestyle=\"-\", color=\"red\", linewidth=1.5)\n",
    "\n",
    "# Adicionar intervalo de confian√ßa\n",
    "plt.fill_between(future_df['ds'], future_df['Pre√ßo Previsto Ajustado Inferior'], future_df['Pre√ßo Previsto Ajustado Superior'], color='gray', alpha=0.3, label=\"Intervalo de Confian√ßa\")\n",
    "\n",
    "plt.title(title_text)\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Pre√ßo (US$)\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Criar tabela com as previs√µes futuras\n",
    "tabela_previsoes = future_df[['ds', 'Pre√ßo Previsto Ajustado', 'Pre√ßo Previsto Ajustado Inferior', 'Pre√ßo Previsto Ajustado Superior']]\n",
    "tabela_previsoes.columns = ['Data', 'Pre√ßo Previsto Ajustado', 'Intervalo Inferior', 'Intervalo Superior']\n",
    "\n",
    "# Exibir a tabela no console\n",
    "print(\"\\nTabela de Previs√µes Futuras (2025-2026):\")\n",
    "print(tabela_previsoes)\n",
    "\n",
    "# Salvar a tabela como um arquivo CSV\n",
    "tabela_previsoes.to_csv('dados/previsoes_futuras.csv', index=False)\n",
    "print(\"\\nTabela de previs√µes salva como 'previsoes_futuras.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20. Criar funcao para gerar tabela automaticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para criar tabela de previs√µes a partir de uma data espec√≠fica\n",
    "def criar_tabela_previsoes(data_inicio, dias_futuros, df_inicial):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para criar uma tabela de previs√µes a partir de uma data espec√≠fica.\n",
    "    :param data_inicio: Data inicial no formato 'YYYY-MM-DD'.\n",
    "    :param dias_futuros: N√∫mero de dias para prever no futuro.\n",
    "    :param df_inicial: DataFrame inicial com os dados hist√≥ricos.\n",
    "    :return: DataFrame com as previs√µes.\n",
    "    \"\"\"\n",
    "    # Carregar os modelos salvos\n",
    "    prophet = joblib.load('modelo/modelo_prophet.pkl')\n",
    "    model_xgb = joblib.load('modelo/modelo_xgboost.pkl')\n",
    "\n",
    "    # Criar DataFrame com as datas futuras\n",
    "    datas_futuras = pd.date_range(start=data_inicio, periods=dias_futuros, freq='D')\n",
    "    future_df = pd.DataFrame({'ds': datas_futuras})\n",
    "\n",
    "    # Fazer previs√µes com o Prophet\n",
    "    prophet_future = prophet.predict(future_df)\n",
    "\n",
    "    # Mesclar previs√µes do Prophet com o DataFrame futuro\n",
    "    future_df = future_df.merge(prophet_future[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], on='ds', how='left')\n",
    "\n",
    "    # Calcular res√≠duos previstos pelo XGBoost\n",
    "    # Para isso, precisamos dos √∫ltimos 7 res√≠duos hist√≥ricos\n",
    "    ultimos_residuos = df_inicial['Res√≠duo'].tail(7).values\n",
    "    if len(ultimos_residuos) < 7:\n",
    "        raise ValueError(\"N√£o h√° dados hist√≥ricos suficientes para prever o res√≠duo.\")\n",
    "\n",
    "    # Criar features para o XGBoost\n",
    "    features_xgb = {f'Res√≠duo_Lag_{i+1}': ultimos_residuos[-(i+1)] for i in range(7)}\n",
    "    features_xgb = pd.DataFrame([features_xgb])\n",
    "\n",
    "    # Prever o res√≠duo com o XGBoost\n",
    "    residuo_previsto = model_xgb.predict(features_xgb)[0]\n",
    "\n",
    "    # Ajustar as previs√µes do Prophet com o res√≠duo previsto\n",
    "    future_df['Pre√ßo Previsto Ajustado'] = future_df['yhat'] + residuo_previsto\n",
    "    future_df['Pre√ßo Previsto Ajustado Inferior'] = future_df['yhat_lower'] + residuo_previsto\n",
    "    future_df['Pre√ßo Previsto Ajustado Superior'] = future_df['yhat_upper'] + residuo_previsto\n",
    "\n",
    "    # Renomear colunas\n",
    "    future_df.rename(columns={\n",
    "        'ds': 'Data',\n",
    "        'Pre√ßo Previsto Ajustado': 'Pre√ßo Previsto',\n",
    "        'Pre√ßo Previsto Ajustado Inferior': 'Valor M√≠nimo Esperado',\n",
    "        'Pre√ßo Previsto Ajustado Superior': 'Valor M√°ximo Esperado'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Arredondar os valores para 2 casas decimais\n",
    "    future_df = future_df.round(2)\n",
    "\n",
    "    # Selecionar colunas relevantes\n",
    "    tabela_previsoes = future_df[['Data', 'Pre√ßo Previsto', 'Valor M√≠nimo Esperado', 'Valor M√°ximo Esperado']]\n",
    "\n",
    "    return tabela_previsoes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTANDO FUNCAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testar a fun√ß√£o de criar tabela de previs√µes\n",
    "data_inicio = '2025-01-01'  # Data inicial para previs√µes\n",
    "dias_futuros = 30  # N√∫mero de dias para prever\n",
    "try:\n",
    "    tabela_previsoes = criar_tabela_previsoes(data_inicio, dias_futuros, df)\n",
    "    print(\"\\nTabela de Previs√µes Futuras:\")\n",
    "    print(tabela_previsoes)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao criar tabela de previs√µes: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
